class GaussianClassifier:
    """
    A class for Gaussian classifier without Naive assumption.

    Attributes:
    n_features (int): number of features in the data.
    n_classes (int): number of classes in the data.
    means (array): an array of shape (n_classes, n_features) that contains
                   the mean values of each feature for each class.
    cov (array): an array of shape (n_classes, n_features, n_features) that
                 contains the covariance matrices for each class.
    priors (array): an array of shape (n_classes) that contains the prior
                    probabilities for each class.

    Methods:
    fit(X, y): calculates the mean, covariance and prior for each class from
               the input data and target values.
    predict_proba(X): calculates the posterior probabilities of each class given the input data.
    predict(X): returns the class with the highest posterior probability for each input data.
    """

    def __init__(self, reject_lambda=None):
        self.reject_lambda = reject_lambda

    def fit(self, X, y):
        """
        Fits the Gaussian classifier to the training data.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The training input samples.

        y : array-like of shape (n_samples,)
            The target values.

        Returns
        -------
        self : object
            Returns the instance itself.
        """
        n_samples, n_features = X.shape

        self.n_features = n_features
        self.n_classes = len(np.unique(y))

        self.means = np.zeros((self.n_classes, self.n_features))
        self.cov = np.zeros((self.n_classes, self.n_features, self.n_features))
        self.priors = np.zeros(self.n_classes)  # prior probabilities for each class

        # calculate the mean and variance of X given c for each class
        for c in range(self.n_classes):
            X_c = X[c == y]
            self.means[c] = X_c.mean(axis=0)
            self.cov[c] = np.cov(X_c, rowvar=False)
            self.priors[c] = len(X_c) / n_samples

    def predict_proba(self, X):
        """ "
        Calculates the posterior probabilities of each class given the input data.

        Args:
            X (array): an array of shape (n_samples, n_features) containing the input data.

        Returns:
            posteriors (array): an array of shape (n_samples, n_classes) containing the posterior
                                probabilities of each class given the input data.
        """
        assert X.ndim == 2 and X.shape[1] == self.n_features
        posteriors = np.zeros((X.shape[0], self.n_classes))

        # loop for each sample of in X
        for idx in range(X.shape[0]):
            x = X[idx]
            # loop for each class and calculate P(c_i|x)
            for c in range(self.n_classes):
                prior = self.priors[c]
                # each conditional probability P(x|c_i) follows a normal distribution
                likelihood = multivariate_normal.pdf(
                    x, mean=self.means[c], cov=self.cov[c]
                )
                posteriors[idx, c] = prior * likelihood

        # normalize by the evidence term
        posteriors /= posteriors.sum(1, keepdims=True)

        return posteriors

    def predict(self, X):
        """
        Returns the class with the highest posterior probability for each input data.

        Args:
            X (array): an array of shape (n_samples, n_features) containing the input data.

        Returns:
            predictions (array): an array of shape (n_samples) containing the predicted class
                                 for each input data.
        """
        probs = self.predict_proba(X)
        if self.reject_lambda is not None:
            lambdas = np.expand_dims(
                np.ones((probs.shape[0])) * (1 - self.reject_lambda), axis=1
            )
            return np.argmax(np.hstack([self.predict_proba(X), lambdas]), axis=1)

        return np.argmax(probs, axis=1)
